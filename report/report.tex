\documentclass{sig-alternate-05-2015}
\usepackage{graphicx}
\graphicspath{ {images/} }

\begin{document}


\title{Citi Bike share analysis}  
\subtitle{[Project Report - 061]}
\subtitle{\url{https://gitlab.com/cloudmesh_fall2016/project-061.git}}

\numberofauthors{1} 

\author{
\alignauthor
Aruna Kumaraswamy\\
F16-DG-4034\\
       \affaddr{Indiana University}\\
       \email{akumaras@iu.edu}
}
\date{Anticipated: 09 December 2016}

\maketitle

\begin{abstract}
    Purpose of this project is to analyze the NYC Citi Bike share system data in batch and streaming mode. Following report summarizes the finding based on the September 2016 bike share data. Report will also provide instructions on installing the necessary software, build and deploy the software created for this project.
    
    This is a draft version. Anticipated completion date is December 9, 2016.
\end{abstract}


\section{Introduction}
Apache Flink is used in this project to process the data in batch and streaming mode. There are 3 main components in this project
\begin{itemize}
    \item BikeRentTrendByAge
    \item BikeRentTrendByGender
    \item LiveStationStatusStream
\end{itemize}
Components are built in Java. Maven is used for building the components.
\subsection {Bike Rent Trend - By Age}
Objective of this analysis is to find in which age group bike share is popular. This component takes csv file as input. For age group analysis, we are interested only in the age, so we skip all the other columns in the spreadsheet. Based on the age group, we decide if the bike rider is Boomer I, Boomer II, Gen X, Gen Y or Gen Z. Invalid age in the data is filtered. Final result is the count of the age groups for September 2016. Figure 1 depicts the visualization for this batch program. Visualization is created using a python program.

\begin{figure}[!ht]
\includegraphics[width=8cm, height=5cm]{tripsbygeneration}
 \caption{Trend By age}\label{F:small}
\end{figure}

\break
\subsection {Bike Rent Trend - By Gender}
Objective of this analysis is to find whether bike ride is popular among men or women. This component takes CSV file as input and creates a CSV output. We are interested in trip date, gender column of the spreadsheet, so we skip other columns. We also filter unknown gender. We transform the input data using tables
and join them to produce the desired CSV output. Figure 2 is the visualization for this batch program. Visualization is created using python program.

\begin{figure}[!ht]
\includegraphics[width=8cm, height=5cm]{tripsbygender}
 \caption{Trend By gender}\label{F:small}
\end{figure}
\subsection {Live Station Status Stream}
Live station status feed is used to check the availability of bikes across all stations. If the bike availability of a station is less than 2 then those stations are filtered. Result is pushed to elastic search. Kibana is used for visualization of real-time alerts across geographic map. Figure 3 is a representation on Geo map done via Kibana.

\begin{figure}[!ht]
\includegraphics[width=8cm, height=5cm]{bikealerts}
 \caption{Bike alerts}\label{F:small}
\end{figure}


\section{Technology}
\subsection{Apache Flink}
When I wrote the initial proposal for this project, I was planning to use Spark. I was interested in deploying a lambda architecture using spark and kafka. More I read about flink, it became obvious that flink is ideal for both batch and streaming data. Even though sparks supports streaming, it is usually a micro batch.

\cite{kjacobs} Figure 4 and Figure 5 shows the comparison between spark and flink.

\begin{figure}[!ht]
\includegraphics[width=8cm, height=5cm]{disk-spark_flink}
 \caption{Spark Vs Flink Disk I/O}\label{F:small}
\end{figure}

\begin{figure}[!ht]
\includegraphics[width=8cm, height=5cm]{spark_flink_latency}
 \caption{Latency comparison spark vs flink}\label{F:small}
\end{figure}
\break
\break

\subsection{Elastic search and Kibana}
In this project I am using elastic search and Kibana for streaming visualization. It is based on the training on flink by data artisan \cite{artisan}. Elastic search indexes are created via curl or Kibana appsense. LiveStationStatusStream component fetches data from bike share realtime feed. It can be modified to continuously fetch real time data. Current implementation is to show the behaviour of data streaming via real time feed. This data is cleansed, filtered and sent to Elastic search sink specifying the index we created via curl. Kibana can now be used to setup indexes, time characteric and search to display the bike alert data in geo map. Kibana does not allow download of the visualization, hence the   of kibana is submitted in this report.


\section {Installation}
Flink - Install flink version 1.1.3 
\break
Elastic search - Install version 2.3.5
\break
Kibana - 4.5.4 (with appsense plugin)
Python 2.7\break

\section {Build and Deploy}

Clone GIT repository

\subsection {Step1 Build Java code}
Build java code using \break
mvn clean package

\subsection {Step2 Prepare data}
Use wget or bitsadmin to get trips data from \break
https://s3.amazonaws.com/tripdata/201609-citibike-tripdata.zip
\break
Flink is unable to process ZIP directly. So unzip the data file.


\subsection {Step 3 Elastic Search Index}
Start Kibana
Go to http://localhost:5601/appsense
Create the citi-bikes index (Refer data instruction in GIT)
Start Elastic Search


\subsection {Step 4 Run Flink}
Refer to README.rst in GIT for detailed instructions on how 
to run batch and stream processing components in Flink.
\break
\break

\section {Conclusion}
Apache Flink offered ease of use and better performance to perform analysis in batch environment. SQL processing in batch mode simplifies data preparation and storage.
\break
Stream Execution environment has rich set of features and connector. Even though Table API is same for batch and stream, I had difficulty getting Kafka stream to dump to a table sink.   
\break
Flink does not have a REST API similar to Spark to submit jobs, hence creating a web dashboard would take more effort.

\bibliographystyle{abbrv}
\bibliography{report} 
\end{document}
